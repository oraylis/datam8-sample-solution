# Macro Import ----------
{% import 'macro/column_declaration_stage.jinja2' as column_declaration %}
{% import "macro/common_python_snippets.py.jinja2" as py_snippets %}

{%- for entity in model.get_stage_entity_list() %}
  {%- set table = entity.model_object.entity %}
  {%- set layer_name = entity.model_object.type.value %}
  {%- set full_table_name = table.dataProduct + "_" + table.dataModule + "_" + table.name %}
  {%- set layer_full_table_name = layer_name + "." + full_table_name %}
  {%- set file_path = helper.build_path("notebooks", SystemProperties().stage_folder, "ddl", table.dataProduct, table.dataModule, table.name) %}
>>>>>>>>>> {{ file_path }}.py | py
# Databricks notebook source
# MAGIC %md
# MAGIC # DDL for {{entity.model_object.type.value}}.{{full_table_name}}

# COMMAND ----------

{% include "__collections/include/ddl_type_mapping.py.jinja2" %}

# COMMAND ----------

# MAGIC %md
# MAGIC ## Get variable values

# COMMAND ----------

{{ py_snippets.common_variables(entity.model_object.type.value, entity, SystemProperties) }}

# COMMAND ----------

{{- column_declaration.ddl_struct_type(model, table.attribute) }}

# COMMAND ----------

# DBTITLE 1,Define new partitions
{%- set partitions = (
    "__Year",
    "__Month",
    "__Day",
    "__InsertTimestampUTC",
) %}
new_partitions = (
  {%- for p in partitions %}
  "{{p}}",
  {%- endfor %}
)

# COMMAND ----------

# DBTITLE 1,Define DDL statement
ddl = """
CREATE TABLE `%(catalog)s`.`%(schema)s`.`%(table)s`
(
    {{ column_declaration.ddl_column_declaration(model, table.attribute) }}
)
USING DELTA
PARTITIONED BY (
{%- for p in partitions %}
    `{{p}}`{{ "," if not loop.last }}
{%- endfor %}
)
""" % {
    "catalog": catalog.name,
    "schema": zone,
    "table": full_table_name,
}

# COMMAND ----------

# DBTITLE 1,Define refactored columns
refactored_columns = []

# COMMAND ----------

{% include "__collections/include/ddl_schema_migration.py.jinja" %}

# COMMAND ----------

<<<<<<<<<< {{ file_path }}.py | py
{%- endfor -%}
